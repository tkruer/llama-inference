# llama-inference

---

Llama-inference is a simple implementation of Karpathy's [llama2.c](https://github.com/karpathy/llama2.c) as a Go net/http webserver. 
The backbone of this project is really rooted around using [go-llama2](https://github.com/tmc/go-llama2).

This for now is just a fun weekend project to continue to learn the MLOps side of things and break away from using Python as a backend.


